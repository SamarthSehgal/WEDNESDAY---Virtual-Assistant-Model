# ğŸŒŸ WEDNESDAY â€“ Virtual Assistant Model

**WEDNESDAY** is a desktop-based intelligent voice assistant powered by **Deep Learning (TensorFlow/Keras)** for Natural Language Understanding (NLU).  
It combines **offline reliability** with **online intelligence**, giving you a truly hybrid assistant that works seamlessly even without internet access.

---

## âœ¨ Features

### ğŸ”¹ **Hybrid Operation**
- Works **offline** for essential tasks (reminders, system control, and local knowledge base).  
- Uses the **internet** for advanced queries like web searches and Wikipedia lookups.

### ğŸ§  **ML-Powered NLU**
- Uses a trained **Keras model (`chat_model.h5`)** for high-accuracy **intent recognition**.  
- Understands diverse voice and text-based commands.

### ğŸ“˜ **Offline Knowledge Base**
- Fast retrieval of factual information from a local dataset (`general_knowledge_qa.csv`).  
- Uses **semantic search** for context-aware question matching.

### âš™ï¸ **Task Automation**
- Perform desktop operations hands-free using commands like:
  - â€œOpen Calculatorâ€
  - â€œIncrease volumeâ€
  - â€œTake a screenshotâ€
- Built with `pyautogui` and `os` libraries for smooth automation.

### âš¡ **Caching**
- Implements a **search caching system (`search_cache.json`)** to:
  - Minimize repeated API calls
  - Increase web response speed

---

ğŸ› ï¸ Installation & Setup

Follow these steps to set up and run Wednesday on your system.

### 1ï¸âƒ£ **Clone the Repository**

bash
git clone https://github.com/SamarthSehgal/WEDNESDAY---Virtual-Assistant-Model.git
cd WEDNESDAY---Virtual-Assistant-Model

### 2ï¸âƒ£ **Create a Virtual Environment (Recommended)**
python -m venv venv
# On Windows
.\venv\Scripts\activate
# On macOS/Linux
source venv/bin/activate

### 3ï¸âƒ£ **Install Dependencies**

Install all required libraries listed in the requirements.txt file:

pip install -r requirements.txt

If the file is missing, manually install the core dependencies (listed below in Section II).

### 4ï¸âƒ£ **Load the ML Model**

Ensure these files are placed in the project root directory:
chat_model.h5
tokenizer.pkl
label_encoder.pkl

These files are required for natural language understanding and intent classification.

### 5ï¸âƒ£ **Run the Assistant**
python main.py

For the text-based version, use:
python main_text.py

### ğŸ§© **Project Structure**
WEDNESDAY---Virtual-Assistant-Model/
â”‚
â”œâ”€â”€ main.py                  # Voice-based assistant
â”œâ”€â”€ main_text.py             # Text-based console assistant
â”œâ”€â”€ intents.json             # Intent training data
â”œâ”€â”€ chat_model.h5            # Trained NLU model
â”œâ”€â”€ tokenizer.pkl            # Tokenizer for preprocessing
â”œâ”€â”€ label_encoder.pkl        # Label encoder for class mapping
â”œâ”€â”€ knowledge_base.py        # Offline knowledge retrieval system
â”œâ”€â”€ internet_search_ddg.py   # Web search using DuckDuckGo API
â”œâ”€â”€ general_knowledge_qa.csv # Local dataset for knowledge base
â”œâ”€â”€ search_cache.json        # Caching for repeated searches
â”œâ”€â”€ logs/                    # Interaction logs generated automatically
â””â”€â”€ README.md                # Project documentation

### ğŸ’¾ **Logging & Debugging**

All assistant interactions are logged in:
logs/assistant_log.txt

Each entry records:
1.User input
2.Intent classification & confidence score
3.Knowledge base & semantic similarity scores
4.Final decision path (Intent / KB / Web)
5.Timestamped response

### ğŸ‘¨â€ğŸ’» **Author**

Samarth Sehgal
